# Automated Caption Generator â€” Full Stack Application

A comprehensive React + TypeScript frontend with Python Flask backend for AI-powered video and image caption generation using OpenAI's Whisper model.

## ğŸš€ Features

### 1. Image Caption Streaming
- Upload images and watch AI generate continuous, contextual meme-style captions in real-time
- Multiple style options (meme, casual, formal, aesthetic)
- Multi-language support

### 2. Continuous Video Captioning  
- Generate timestamped captions throughout your video using Whisper AI
- **Input/Output Language Selection**: Choose the language of your input video and the desired output language for captions
- Real-time transcription and translation
- Export formats: SRT, VTT, and custom formats
- Perfect for subtitles and accessibility

### 3. Video Summary Caption
- Generate a single, comprehensive caption that summarizes the entire video content
- Ideal for video descriptions, social media posts, and content overviews
- Download video with embedded soft subtitles

### 4. Backend Integration
- Python Flask backend with OpenAI Whisper integration
- Real video processing with FFmpeg
- Automatic fallback to mock API when backend is unavailable

## ğŸ“‹ Prerequisites

Before running the application, make sure you have:

1. **Python 3.8 or higher** - [Download Python](https://python.org)
2. **Node.js 16 or higher** - [Download Node.js](https://nodejs.org)
3. **FFmpeg** - Required for video processing
   
   **Windows Installation Options:**
   - Download from [FFmpeg Official Site](https://ffmpeg.org/download.html)
   - Using Chocolatey: `choco install ffmpeg`
   - Using Winget: `winget install FFmpeg`

## ğŸ”§ Quick Setup (Windows)

1. **Automated Setup** (Recommended):
   ```cmd
   setup.bat
   ```
   This script will:
   - Check all prerequisites
   - Set up Python virtual environment
   - Install all dependencies
   - Configure the application

2. **Start Both Servers**:
   ```cmd
   start.bat
   ```
   This will start both backend and frontend servers automatically.

## ğŸ› ï¸ Manual Setup

### Backend Setup

1. **Navigate to backend directory**:
   ```cmd
   cd backend
   ```

2. **Create virtual environment**:
   ```cmd
   python -m venv venv
   venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```cmd
   pip install -r requirements.txt
   ```

4. **Start backend server**:
   ```cmd
   python app.py
   ```
   Backend will be available at: `http://localhost:5000`

### Frontend Setup

1. **Install Node.js dependencies**:
   ```cmd
   npm install
   ```

2. **Start development server**:
   ```cmd
   npm run dev
   ```
   Frontend will be available at: `http://localhost:5173`

## ğŸŒ API Endpoints

### Backend API (http://localhost:5000)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Check server status |
| `/generate-captions` | POST | Generate captions from video |
| `/generate-video-with-captions` | POST | Create video with embedded captions |
| `/download/<filename>` | GET | Download generated video |
| `/download-srt` | POST | Download SRT subtitle file |

### Request Parameters

**For caption generation:**
- `video`: Video file (MP4, AVI, MOV, MKV, WebM, FLV, WMV)
- `task`: "transcribe" or "translate" (optional)
- `style`: "formal", "meme", "aesthetic", "casual" (optional)
- `language`: Target language code (optional)

## ğŸ¯ Usage

1. **Start both servers** using `start.bat` or manually
2. **Open your browser** to `http://localhost:5173`
3. **Upload a video file** and select your options
4. **Choose your processing mode**:
   - **Simple Caption**: Get a summary of the video content
   - **Continuous Captions**: Get timestamped captions with export options
   - **Video with Captions**: Generate and download video with embedded subtitles

## ğŸ”„ Fallback System

The application includes an intelligent fallback system:
- **Backend Available**: Uses real Whisper AI for processing
- **Backend Unavailable**: Automatically falls back to mock API
- **Visual Indicators**: Shows backend status in the UI

## ğŸ“ Project Structure

```
cbit/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ pages/              # Page components
â”‚   â”‚   â”œâ”€â”€ api.ts              # API client with backend integration
â”‚   â”‚   â””â”€â”€ mockApi.ts          # Fallback mock API
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # Flask server with Whisper integration
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ uploads/                # Temporary upload directory
â”‚   â”œâ”€â”€ outputs/                # Generated files directory
â”‚   â””â”€â”€ README.md              # Backend-specific documentation
â”œâ”€â”€ setup.bat                   # Automated setup script
â”œâ”€â”€ start.bat                   # Start both servers
â””â”€â”€ README.md                   # This file
```

## ğŸš¨ Troubleshooting

### Common Issues

1. **FFmpeg not found**
   - Ensure FFmpeg is installed and added to system PATH
   - Restart command prompt after installation

2. **Python virtual environment issues**
   - Delete `backend/venv` folder and recreate: `python -m venv venv`

3. **Port conflicts**
   - Backend runs on port 5000, frontend on 5173
   - Make sure these ports are available

4. **Memory issues**
   - Whisper model requires significant RAM
   - Consider using a smaller model in `backend/app.py`

### Model Sizes (Edit in backend/app.py)

- `tiny`: Fastest, least accurate (~39 MB)
- `base`: Fast, decent accuracy (~74 MB)
- `small`: Good balance (~244 MB) - **Default**
- `medium`: Better accuracy (~769 MB)
- `large`: Best accuracy (~1550 MB)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test both frontend and backend
5. Submit a pull request

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- OpenAI Whisper for speech recognition
- Flask for the backend framework
- React and Vite for the frontend
- FFmpeg for video processing
